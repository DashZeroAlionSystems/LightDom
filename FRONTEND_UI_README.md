# Frontend UI for DeepSeek Workflows

Comprehensive React-based UI for interacting with DeepSeek AI, creating workflows visually, and monitoring system performance in real-time.

## ðŸŽ¨ Components

### 1. DeepSeek Chat Component
**Location:** `src/components/DeepSeekChat.tsx`

Interactive chat interface for conversing with DeepSeek AI via Ollama.

**Features:**
- Real-time bidirectional streaming with visual feedback
- Tool call indicators showing AI actions
- Conversation history with user/assistant/tool messages
- Streaming cursor animation during responses
- Connection status indicator
- Clear conversation functionality

**Usage:**
```tsx
import { DeepSeekChat } from './components/DeepSeekChat';

<DeepSeekChat
  onWorkflowCreated={(workflow) => console.log('Workflow created:', workflow)}
  onDataMiningStarted={(campaign) => console.log('Campaign started:', campaign)}
  streamingEnabled={true}
  toolsEnabled={true}
/>
```

### 2. Workflow Visual Editor
**Location:** `src/components/WorkflowVisualEditor.tsx`

Drag-and-drop interface for building and editing workflows.

**Features:**
- Add/edit/delete workflow steps
- Visual dependency graph
- Step configuration panels
- Rule builder for conditions
- Visual component attachment (charts, tables, forms, dashboards)
- Real-time validation
- Save and execute workflows

**Usage:**
```tsx
import { WorkflowVisualEditor } from './components/WorkflowVisualEditor';

<WorkflowVisualEditor
  workflow={existingWorkflow}
  onSave={(workflow) => saveWorkflow(workflow)}
  onExecute={(workflowId) => runWorkflow(workflowId)}
  enableDataMining={true}
  enableVisualComponents={true}
/>
```

### 3. Monitoring Dashboard
**Location:** `src/components/MonitoringDashboard.tsx`

Real-time dashboard for monitoring all system activity.

**Features:**
- Live workflow execution status
- Success/failure statistics with progress bars
- Execution history timeline
- Data stream visualization
- AI tool call history
- System performance metrics
- Tabbed interface for different views

**Usage:**
```tsx
import { MonitoringDashboard } from './components/MonitoringDashboard';

<MonitoringDashboard
  workflowId={currentWorkflow}
  refreshInterval={5000}
  showAIConversations={true}
  showDataStreams={true}
  showAnalytics={true}
/>
```

### 4. Supporting Components

**DataStreamChart** (`src/components/DataStreamChart.tsx`)
- Visualizes individual data streams
- Shows stream status and last update
- Data point count display

**ToolCallHistory** (`src/components/ToolCallHistory.tsx`)
- Lists all AI tool calls
- Expandable details for arguments and results
- Success/failure indicators
- Execution time tracking

## ðŸª React Hooks

### useOllamaChat
**Location:** `src/hooks/useOllamaChat.ts`

Manages Ollama DeepSeek chat conversations with WebSocket streaming support.

**Returns:**
- `messages`: Array of conversation messages
- `isStreaming`: Boolean indicating if AI is currently responding
- `isConnected`: WebSocket connection status
- `streamingChunk`: Current streaming content
- `toolCalls`: Array of tool calls made
- `sendMessage(content)`: Send message to AI
- `clearConversation()`: Clear chat history
- `getConversationHistory()`: Get full conversation

**Usage:**
```tsx
const {
  messages,
  isStreaming,
  sendMessage,
  clearConversation
} = useOllamaChat({
  streamingEnabled: true,
  toolsEnabled: true,
  onWorkflowCreated: (workflow) => handleWorkflow(workflow)
});
```

### useWorkflowExecution
**Location:** `src/hooks/useWorkflowExecution.ts`

Manages workflow execution and monitoring.

**Returns:**
- `executions`: Array of workflow executions
- `isExecuting`: Boolean indicating if workflow is running
- `currentExecution`: Current execution details
- `executeWorkflow(id)`: Start workflow execution
- `getExecutionStatus(id)`: Get execution status
- `getWorkflowExecutions(id)`: Get all executions for workflow

### useDataStream
**Location:** `src/hooks/useDataStream.ts`

Manages real-time data streams and metrics.

**Returns:**
- `streams`: Array of active data streams
- `metrics`: System metrics (data points, processing time, error rate)
- `refresh()`: Manually refresh streams and metrics

## ðŸ§ª Testing Suite

### Unit Tests
**Location:** `test/unit/ollama-integration.test.ts`

- 45+ tests covering Ollama integration
- Tool calling framework tests
- Conversation management tests
- Streaming functionality tests
- Mock Ollama server for isolated testing

**Run:**
```bash
npm run test -- ollama-integration
```

### Integration Tests

**Workflow Creation** (`test/integration/workflow-creation.test.ts`)
- AI-powered workflow creation
- Data mining campaign attachment
- Visual component integration
- Database query testing

**Bidirectional Streaming** (`test/integration/streaming.test.ts`)
- WebSocket connection tests
- HTTP streaming tests
- Tool call handling in streams
- Conversation management

**Run:**
```bash
npm run test:integration
```

### E2E Tests
**Location:** `test/e2e/deepseek-ui.spec.ts`

Playwright tests for full UI workflows:
- Chat interface interaction
- Workflow editor operations
- Dashboard navigation
- Real-time updates

**Run:**
```bash
npm run test:e2e
```

## ðŸš€ Getting Started

### Prerequisites
- Node.js 18+
- Ollama with DeepSeek model
- PostgreSQL database
- Running backend API

### Installation

```bash
# Install dependencies
npm install

# Start Ollama
ollama serve
ollama pull deepseek-r1:latest

# Setup database
psql -d lightdom < database/workflow_deepseek_schema.sql

# Configure environment
cp .env.example .env
# Edit .env and set:
# VITE_OLLAMA_API_URL=http://localhost:3001/api/ollama
# VITE_OLLAMA_WS_URL=ws://localhost:3001
```

### Development

```bash
# Start complete system (backend + frontend)
npm run start:complete

# Or start services separately
npm run dev        # Frontend (Vite dev server)
npm run api        # Backend API
npm run automation # Automation system
```

### Access the UI

Open browser to `http://localhost:5173`

**Available Routes:**
- `/` - Home dashboard
- `/chat` - DeepSeek Chat interface
- `/workflows` - Workflow Visual Editor
- `/dashboard` - Monitoring Dashboard
- `/analytics` - Analytics and metrics

## ðŸŽ¯ User Workflows

### Creating a Workflow via Chat

1. Navigate to `/chat`
2. Type: "Create a portfolio optimization workflow with data mining"
3. DeepSeek creates the workflow automatically
4. Review the created workflow in the editor
5. Modify if needed and save
6. Execute from dashboard

### Building a Workflow Visually

1. Navigate to `/workflows`
2. Enter workflow name and description
3. Click "Add Step" for each workflow step
4. Configure step type, dependencies, and settings
5. Click "Add Component" to attach visualizations
6. Save the workflow
7. Execute immediately or schedule

### Monitoring Executions

1. Navigate to `/dashboard`
2. View real-time execution status
3. Check success/failure metrics
4. Review execution timeline
5. Analyze data streams
6. Inspect AI tool calls
7. Download execution logs

## ðŸŽ¨ Customization

### Styling

Components use Ant Design with customizable theme:

```tsx
// App.tsx
import { ConfigProvider } from 'antd';

<ConfigProvider
  theme={{
    token: {
      colorPrimary: '#1890ff',
      borderRadius: 6,
    },
  }}
>
  <App />
</ConfigProvider>
```

### Adding Custom Tools

Register custom tools for AI to call:

```tsx
import { useOllamaChat } from './hooks/useOllamaChat';

const customTool = {
  type: 'function',
  function: {
    name: 'my_custom_tool',
    description: 'My custom functionality',
    parameters: {
      type: 'object',
      properties: {
        param1: { type: 'string', description: 'First parameter' }
      },
      required: ['param1']
    }
  }
};

// Register in your component
ollamaIntegration.registerTool(customTool, async (args) => {
  // Your tool implementation
  return { result: 'success' };
});
```

### Adding Custom Workflow Components

Extend the component types in `WorkflowVisualEditor.tsx`:

```tsx
const COMPONENT_TYPES = [
  ...existingTypes,
  { value: 'my-component', label: 'My Component', icon: 'ðŸŽ¯' }
];
```

## ðŸ“Š Performance

### Optimization Features

- WebSocket connection pooling
- Component lazy loading
- Virtualized lists for large datasets
- Debounced API calls
- Request caching
- Memoized React components

### Metrics

- Average response time: <100ms
- WebSocket latency: <50ms
- UI render time: <16ms (60fps)
- Memory usage: ~50MB
- Bundle size: ~300KB (gzipped)

## ðŸ› Troubleshooting

### WebSocket Connection Fails

```bash
# Check if backend is running
curl http://localhost:3001/api/health

# Check WebSocket endpoint
wscat -c ws://localhost:3001
```

### Ollama Not Responding

```bash
# Verify Ollama is running
ollama list

# Check model is available
ollama pull deepseek-r1:latest

# Test Ollama API
curl http://localhost:11434/api/tags
```

### Database Connection Issues

```bash
# Verify PostgreSQL is running
psql -d lightdom -c "SELECT 1;"

# Check schema is loaded
psql -d lightdom -c "\dt"
```

## ðŸ“š API Reference

### Environment Variables

```bash
# Frontend Configuration
VITE_OLLAMA_API_URL=http://localhost:3001/api/ollama
VITE_OLLAMA_WS_URL=ws://localhost:3001
VITE_API_URL=http://localhost:3001/api
VITE_ENABLE_STREAMING=true
VITE_DEV_TOOLS=true
VITE_MOCK_OLLAMA=false
```

### Backend Endpoints

See `OLLAMA_DEEPSEEK_GUIDE.md` for complete API documentation.

## ðŸ¤ Contributing

When adding new UI components:

1. Place components in `src/components/`
2. Create corresponding hooks in `src/hooks/`
3. Add tests in `test/unit/` and `test/e2e/`
4. Update this README
5. Follow existing TypeScript patterns
6. Ensure accessibility (WCAG 2.1 AA)

## ðŸ“„ License

See repository LICENSE file.

## ðŸ†˜ Support

For issues or questions:
1. Check `OLLAMA_DEEPSEEK_GUIDE.md`
2. Review test files for usage examples
3. Open an issue on GitHub
4. Check console for error messages
