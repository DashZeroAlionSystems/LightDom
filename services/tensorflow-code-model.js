/**
 * TensorFlow Code Intelligence Model
 * 
 * Advanced ML model for code analysis, pattern recognition, and optimization.
 * 
 * Features:
 * - Code pattern recognition
 * - Error prediction
 * - Code quality scoring
 * - Duplicate detection
 * - Optimization suggestions
 * - Self-learning from outcomes
 * 
 * Based on research:
 * - Google's Code Review AI
 * - Facebook's SapFix
 * - Microsoft's IntelliCode
 * - DeepMind's AlphaCode
 */

import * as tf from '@tensorflow/tfjs-node';
import { EventEmitter } from 'events';
import fs from 'fs/promises';
import path from 'path';

export class TensorFlowCodeModel extends EventEmitter {
  constructor(config = {}) {
    super();
    
    this.config = {
      modelPath: config.modelPath || './models/code-intelligence',
      enableGPU: config.enableGPU || false,
      batchSize: config.batchSize || 32,
      epochs: config.epochs || 100,
      learningRate: config.learningRate || 0.001,
      ...config,
    };

    this.model = null;
    this.vocabulary = new Map();
    this.labelEncoder = new Map();
    this.isTraining = false;
    
    this.stats = {
      trainingSamples: 0,
      accuracy: 0,
      loss: 0,
      predictions: 0,
    };
  }

  /**
   * Initialize or load model
   */
  async initialize() {
    console.log('ðŸ¤– Initializing TensorFlow Code Intelligence Model...');
    
    try {
      // Try to load existing model
      await this.loadModel();
      console.log('âœ… Loaded existing model');
    } catch (error) {
      console.log('âš ï¸  No existing model, creating new one...');
      await this.createModel();
      console.log('âœ… Created new model');
    }
  }

  /**
   * Create new model architecture
   */
  async createModel() {
    // Model for code pattern recognition
    // Architecture: Embedding â†’ LSTM â†’ Dense â†’ Softmax
    
    this.model = tf.sequential({
      layers: [
        // Embedding layer for code tokens
        tf.layers.embedding({
          inputDim: 10000, // Vocabulary size
          outputDim: 128,   // Embedding dimension
          inputLength: 100,  // Max sequence length
        }),
        
        // Bidirectional LSTM for sequence understanding
        tf.layers.bidirectional({
          layer: tf.layers.lstm({
            units: 128,
            returnSequences: true,
          }),
        }),
        
        // Attention mechanism
        tf.layers.dense({
          units: 64,
          activation: 'tanh',
        }),
        
        // Global pooling
        tf.layers.globalAveragePooling1d(),
        
        // Dense layers
        tf.layers.dense({
          units: 256,
          activation: 'relu',
        }),
        tf.layers.dropout({ rate: 0.3 }),
        
        tf.layers.dense({
          units: 128,
          activation: 'relu',
        }),
        tf.layers.dropout({ rate: 0.2 }),
        
        // Output layer (multi-class classification)
        tf.layers.dense({
          units: 50, // Number of pattern types
          activation: 'softmax',
        }),
      ],
    });
    
    // Compile model
    this.model.compile({
      optimizer: tf.train.adam(this.config.learningRate),
      loss: 'categoricalCrossentropy',
      metrics: ['accuracy'],
    });
    
    console.log('ðŸ“Š Model architecture created');
    this.model.summary();
  }

  /**
   * Train model on code samples
   */
  async train(trainingData, validationData = null) {
    if (this.isTraining) {
      throw new Error('Model is already training');
    }
    
    this.isTraining = true;
    console.log(`ðŸŽ“ Training on ${trainingData.length} samples...`);
    
    try {
      // Prepare data
      const { xs, ys } = this.prepareTrainingData(trainingData);
      
      let validationXs, validationYs;
      if (validationData) {
        const validation = this.prepareTrainingData(validationData);
        validationXs = validation.xs;
        validationYs = validation.ys;
      }
      
      // Train model
      const history = await this.model.fit(xs, ys, {
        epochs: this.config.epochs,
        batchSize: this.config.batchSize,
        validationData: validationData ? [validationXs, validationYs] : null,
        callbacks: {
          onEpochEnd: (epoch, logs) => {
            console.log(`Epoch ${epoch + 1}: loss=${logs.loss.toFixed(4)}, acc=${logs.acc.toFixed(4)}`);
            
            this.emit('training:epoch', {
              epoch: epoch + 1,
              loss: logs.loss,
              accuracy: logs.acc,
            });
          },
        },
      });
      
      // Update stats
      this.stats.trainingSamples = trainingData.length;
      this.stats.accuracy = history.history.acc[history.history.acc.length - 1];
      this.stats.loss = history.history.loss[history.history.loss.length - 1];
      
      console.log(`âœ… Training complete! Accuracy: ${(this.stats.accuracy * 100).toFixed(2)}%`);
      
      // Save model
      await this.saveModel();
      
      // Cleanup tensors
      xs.dispose();
      ys.dispose();
      if (validationXs) validationXs.dispose();
      if (validationYs) validationYs.dispose();
      
      return {
        accuracy: this.stats.accuracy,
        loss: this.stats.loss,
        epochs: this.config.epochs,
      };
      
    } catch (error) {
      console.error('Training failed:', error);
      throw error;
    } finally {
      this.isTraining = false;
    }
  }

  /**
   * Predict pattern for code
   */
  async predict(code) {
    if (!this.model) {
      throw new Error('Model not initialized');
    }
    
    // Tokenize code
    const tokens = this.tokenizeCode(code);
    const sequence = this.tokensToSequence(tokens);
    
    // Create tensor
    const input = tf.tensor2d([sequence], [1, sequence.length]);
    
    // Predict
    const prediction = this.model.predict(input);
    const probabilities = await prediction.array();
    
    // Get top predictions
    const topK = 5;
    const results = this.getTopKPredictions(probabilities[0], topK);
    
    // Cleanup
    input.dispose();
    prediction.dispose();
    
    this.stats.predictions++;
    
    return results;
  }

  /**
   * Analyze code patterns
   */
  async analyzePatterns(codeEntities) {
    const patterns = {
      errorPatterns: [],
      duplicateCode: [],
      complexityIssues: [],
      structuralProblems: [],
      optimizations: [],
    };
    
    for (const entity of codeEntities) {
      const prediction = await this.predict(entity.code || entity.signature);
      
      // Classify predictions
      for (const pred of prediction) {
        if (pred.category === 'error_pattern') {
          patterns.errorPatterns.push({
            entity: entity.entity_id,
            pattern: pred.label,
            confidence: pred.probability,
          });
        } else if (pred.category === 'duplicate') {
          patterns.duplicateCode.push({
            entity: entity.entity_id,
            pattern: pred.label,
            confidence: pred.probability,
          });
        } else if (pred.category === 'complexity') {
          patterns.complexityIssues.push({
            entity: entity.entity_id,
            issue: pred.label,
            confidence: pred.probability,
          });
        }
      }
    }
    
    return patterns;
  }

  /**
   * Generate training data from codebase
   */
  async generateTrainingData(codeEntities, issueHistory) {
    const trainingData = [];
    
    // Positive examples (code with known issues)
    for (const issue of issueHistory) {
      const entity = codeEntities.find(e => e.entity_id === issue.related_entity_id);
      if (entity) {
        trainingData.push({
          code: entity.code || entity.signature,
          label: issue.category,
          metadata: {
            severity: issue.severity,
            resolved: issue.status === 'resolved',
          },
        });
      }
    }
    
    // Negative examples (clean code)
    const cleanEntities = codeEntities.filter(e => 
      !issueHistory.some(i => i.related_entity_id === e.entity_id)
    );
    
    for (const entity of cleanEntities.slice(0, trainingData.length)) {
      trainingData.push({
        code: entity.code || entity.signature,
        label: 'clean',
        metadata: {},
      });
    }
    
    return trainingData;
  }

  /**
   * Prepare training data
   */
  prepareTrainingData(data) {
    const sequences = [];
    const labels = [];
    
    for (const sample of data) {
      // Tokenize code
      const tokens = this.tokenizeCode(sample.code);
      const sequence = this.tokensToSequence(tokens);
      
      // Encode label
      const labelIndex = this.encodeLabel(sample.label);
      const oneHot = this.oneHotEncode(labelIndex, 50); // 50 classes
      
      sequences.push(sequence);
      labels.push(oneHot);
    }
    
    // Convert to tensors
    const xs = tf.tensor2d(sequences);
    const ys = tf.tensor2d(labels);
    
    return { xs, ys };
  }

  /**
   * Tokenize code
   */
  tokenizeCode(code) {
    // Simple tokenization (can be improved with proper AST-based tokenization)
    return code
      .toLowerCase()
      .replace(/[^a-z0-9\s]/g, ' ')
      .split(/\s+/)
      .filter(Boolean);
  }

  /**
   * Convert tokens to sequence
   */
  tokensToSequence(tokens) {
    const maxLen = 100;
    const sequence = new Array(maxLen).fill(0);
    
    for (let i = 0; i < Math.min(tokens.length, maxLen); i++) {
      const token = tokens[i];
      
      // Get or create token index
      if (!this.vocabulary.has(token)) {
        this.vocabulary.set(token, this.vocabulary.size + 1);
      }
      
      sequence[i] = this.vocabulary.get(token);
    }
    
    return sequence;
  }

  /**
   * Encode label
   */
  encodeLabel(label) {
    if (!this.labelEncoder.has(label)) {
      this.labelEncoder.set(label, this.labelEncoder.size);
    }
    return this.labelEncoder.get(label);
  }

  /**
   * One-hot encode
   */
  oneHotEncode(index, numClasses) {
    const encoded = new Array(numClasses).fill(0);
    encoded[index] = 1;
    return encoded;
  }

  /**
   * Get top K predictions
   */
  getTopKPredictions(probabilities, k) {
    const predictions = probabilities
      .map((prob, index) => ({
        index,
        probability: prob,
        label: this.decodeLabelIndex(index),
        category: this.getLabelCategory(index),
      }))
      .sort((a, b) => b.probability - a.probability)
      .slice(0, k);
    
    return predictions;
  }

  /**
   * Decode label index
   */
  decodeLabelIndex(index) {
    for (const [label, idx] of this.labelEncoder.entries()) {
      if (idx === index) {
        return label;
      }
    }
    return 'unknown';
  }

  /**
   * Get label category
   */
  getLabelCategory(index) {
    const label = this.decodeLabelIndex(index);
    
    if (label.includes('error')) return 'error_pattern';
    if (label.includes('duplicate')) return 'duplicate';
    if (label.includes('complex')) return 'complexity';
    if (label.includes('struct')) return 'structural';
    
    return 'other';
  }

  /**
   * Save model
   */
  async saveModel() {
    await fs.mkdir(this.config.modelPath, { recursive: true });
    
    await this.model.save(`file://${this.config.modelPath}`);
    
    // Save vocabulary and encoders
    await fs.writeFile(
      path.join(this.config.modelPath, 'metadata.json'),
      JSON.stringify({
        vocabulary: Array.from(this.vocabulary.entries()),
        labelEncoder: Array.from(this.labelEncoder.entries()),
        stats: this.stats,
      }),
      'utf-8'
    );
    
    console.log(`ðŸ’¾ Model saved to ${this.config.modelPath}`);
  }

  /**
   * Load model
   */
  async loadModel() {
    this.model = await tf.loadLayersModel(`file://${this.config.modelPath}/model.json`);
    
    // Load metadata
    const metadata = JSON.parse(
      await fs.readFile(path.join(this.config.modelPath, 'metadata.json'), 'utf-8')
    );
    
    this.vocabulary = new Map(metadata.vocabulary);
    this.labelEncoder = new Map(metadata.labelEncoder);
    this.stats = metadata.stats;
    
    console.log(`ðŸ“¦ Model loaded from ${this.config.modelPath}`);
  }

  /**
   * Get model stats
   */
  getStats() {
    return {
      ...this.stats,
      vocabularySize: this.vocabulary.size,
      numLabels: this.labelEncoder.size,
      modelLoaded: this.model !== null,
    };
  }
}

export default TensorFlowCodeModel;
